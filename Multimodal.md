# Multimodal pretrain
- Two mothods:1.Bert. seq2seq model. 2.CLIP. constrastive pretrained model.

# Muiltimodal Paper
- [Tutorial on Multimodal Machine Learning](https://www.cs.cmu.edu/~morency/MMML-Tutorial-ACL2017.pdf)
- [Open Domain Question Answering Using Early Fusion of Knowledge Bases and Text](https://arxiv.org/pdf/1809.00782.pdf)   
[blog](/Mutilmodal/Open%20Domain%20Question%20Answering%20Using%20Early%20Fusion%20of%20Knowledge%20Bases%20and%20Text.md)
- **Blip** []

## Survey
- [Beyond Just Vision: A Review on Self-Supervised Representation Learning on Multimodal and Temporal Data. SHOHREH DELDARI; HAO XUE; AAQIB SAEED; JIAYUAN HE; DANIEL V. SMITH; FLORA D. SALIM](https://arxiv.org/pdf/2206.02353v2.pdf)
[notebook](/Mutilmodal/Beyond Just Vision A Review on Self-Supervised Representation Learning on Multimodal and Temporal Data.md)


待看论文：
language model：
1. metaLM(Microsoft)
2. Poli(Google)
generalist model
1. Unified IO
2. Uniperciver (V2)
3. Uniperciver MOE

解决的问题：
1. 计算效率问题


论文关系：
![paper relation](/asset/多模态.png)
